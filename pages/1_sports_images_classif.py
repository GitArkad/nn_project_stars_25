import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms
from PIL import Image
import requests
from io import BytesIO
import time
import json
import os

# --- 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ---

@st.cache_data
def load_class_names(json_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫–ª—é—á–∏ –∫ —Ü–µ–ª—ã–º —á–∏—Å–ª–∞–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –≤—ã—Ö–æ–¥–æ–º –º–æ–¥–µ–ª–∏
            return {int(k): v for k, v in data.items()}
    else:
        # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –∫–æ–¥ —Ä–∞–±–æ—Ç–∞–ª
        st.warning(f"–§–∞–π–ª {json_path} –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ classes.json –≤ –ø–∞–ø–∫–µ models.")
        return {i: f"–ö–ª–∞—Å—Å ‚Ññ{i}" for i in range(100)}

@st.cache_resource
def load_trained_model(model_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏."""
    model = models.resnet18()
    model.fc = nn.Linear(model.fc.in_features, 100) 
    state_dict = torch.load(model_path, map_location='cpu')
    model.load_state_dict(state_dict)
    model.eval()
    return model

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π –∏ –æ–±—ä–µ–∫—Ç–æ–≤
MODEL_PATH = 'models/model_sic100.pt'
JSON_PATH = 'models/classes_sic100.json'

CLASS_LABELS = load_class_names(JSON_PATH)
model = load_trained_model(MODEL_PATH)

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–ª—è ResNet
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# --- 2. –ò–ù–¢–ï–†–§–ï–ô–° ---

st.title("‚öΩ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞")

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –≤ session_state (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º, –µ—Å–ª–∏ –ø—É—Å—Ç–æ)
if 'images_archive' not in st.session_state:
    st.session_state.images_archive = []

tab1, tab2 = st.tabs(["üì• –ó–∞–≥—Ä—É–∑–∫–∞", "üîç –ê–Ω–∞–ª–∏–∑"])

with tab1:
    files = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ç–æ", accept_multiple_files=True, key="uploader")
    url = st.text_input("–ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É")
    
    if st.button("–î–æ–±–∞–≤–∏—Ç—å –≤ —Å–ø–∏—Å–æ–∫"):
        if files:
            for f in files:
                st.session_state.images_archive.append(Image.open(f).convert('RGB'))
        if url:
            try:
                res = requests.get(url, timeout=5)
                st.session_state.images_archive.append(Image.open(BytesIO(res.content)).convert('RGB'))
            except:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ —Å—Å—ã–ª–∫–µ.")
        st.success(f"–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –≤ –æ—á–µ—Ä–µ–¥–∏: {len(st.session_state.images_archive)}")

with tab2:
    if not st.session_state.images_archive:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–æ –≤–∫–ª–∞–¥–∫–µ –≤—ã—à–µ.")
    else:
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        c_btn1, c_btn2 = st.columns(2)
        with c_btn1:
            start_analysis = st.button("üöÄ –ù–ê–ß–ê–¢–¨ –ê–ù–ê–õ–ò–ó", type="primary", use_container_width=True)
        with c_btn2:
            if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –≤—Å—ë", use_container_width=True):
                st.session_state.images_archive = []
                st.rerun()

        # –¶–∏–∫–ª –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        for i, img in enumerate(st.session_state.images_archive):
            st.write("---")
            col_img, col_res = st.columns([1, 1.5])
            
            with col_img:
                st.image(img, use_container_width=True, caption=f"–§–æ—Ç–æ ‚Ññ{i+1}")
            
            with col_res:
                if start_analysis:
                    # –õ–æ–≥–∏–∫–∞ –º–æ–¥–µ–ª–∏
                    start_t = time.time()
                    
                    input_tensor = preprocess(img).unsqueeze(0)
                    with torch.no_grad():
                        output = model(input_tensor)
                        probs = F.softmax(output, dim=1)
                        conf, idx = torch.max(probs, dim=1)
                    
                    end_t = time.time()
                    duration = (end_t - start_t) * 1000 # –º—Å
                    
                    # –ü–†–ò–í–Ø–ó–ö–ê –ö–õ–ê–°–°–ê –ö –ù–ê–ó–í–ê–ù–ò–Æ
                    class_id = int(idx.item())
                    # –ë–µ—Ä–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç ‚Äî –≤—ã–≤–æ–¥–∏–º ID
                    name = CLASS_LABELS.get(class_id, f"ID {class_id}")
                    
                    # –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
                    st.success(f"### –†–µ–∑—É–ª—å—Ç–∞—Ç: {name}")
                    st.metric("–¢–æ—á–Ω–æ—Å—Ç—å", f"{conf.item():.2%}")
                    st.write(f"‚è± –í—Ä–µ–º—è: {duration:.2f} –º—Å")
                else:
                    st.write("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≤—ã—à–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞.")
